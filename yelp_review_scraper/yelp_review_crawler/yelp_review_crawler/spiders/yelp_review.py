# -*- coding: utf-8 -*-
from scrapy.spiders import Spider
from scrapy.http import Request
from lxml import html
import time
import datetime
import re

"""Spider class created by scrapy via the scrapy genspider command"""

def extract_first(array_result):
    """Helper method to extract the first item from the array set and turn empty string if it's empty list"""
    if len(array_result) > 0:
        return array_result[0]
    else:
        return ""

def make_searchable_name(input_name):
    """Helper method to convert pizza restaurant name into searchable name (remove punctuation and lower case the string)"""
    if input_name:
        return re.sub(r'[^\w\s]','',input_name.lower())
    else:
        return ""

def clean_parsed_result(parsed_result):
    """Helper method to clean up the string by removing newline char and trim the trailing spaces"""
    if parsed_result is not None:
        return parsed_result.replace("\n", "").strip()

def convert_to_unix_timestamp(str_date):
    """Helper method to convert date into unix timestamp"""
    return time.mktime(datetime.datetime.strptime(str_date, "%m/%d/%Y").timetuple())

def get_current_page(url):
    """Helper method that takes in current yelp review url and determine the page number of the review list"""
    if "&start=" in url:
        #not page 1
        str_page = url.split("=")[-1]
        return (int(str_page)/20)
    else:
        return 1

"""
Constant:
    ROOT_URL: yelp url that will be used to build absolute url
    PAGE_CUT_OFF: hardcoded the review scrapping to max of 10 pages
    
"""
ROOT_URL = 'https://www.yelp.com'
PAGE_CUT_OFF = 10

class YelpReviewSpider(Spider):
    """Spider class generated by scrappy"""
    name = 'yelp_review'
    allowed_domains = ['yelp.com']
    start_urls = ['https://www.yelp.com/search?find_desc=pizza&find_loc=New+York%2C+NY&ns=1']
    #start_urls = ['https://www.yelp.com/biz/julianas-pizza-brooklyn-5?osq=pizza']

    def parse(self, response):
        """
        parsed method used to help spider navigates through the pizza restaurant list
        before passing in the pizza review content to the parse_pizza method.
        """

        #get url for each pizza restaurant
        pizza_urls = response.xpath("//*[@class='regular-search-result']//a[@data-analytics-label='biz-name']/@href").extract()

        #for each pizza biz url, send it to parse_pizza method
        for pizza_url in pizza_urls:
            absolute_url = ROOT_URL + pizza_url
            print("My pizza url is:" + pizza_url)
            yield Request(absolute_url, callback=self.parse_pizza)

        #Try to extract the next url to navigate to next pizza restaurant list page
        next_url = response.xpath("//a[@class='u-decoration-none next pagination-links_anchor']/@href").extract_first()
        if next_url:
            absolute_url = ROOT_URL + next_url
            print("My next page url is:" + absolute_url)
            yield Request(absolute_url, callback=self.parse)




    def parse_pizza(self, response):
        """This method is used to scrap the yelp review page by utilizing xpath."""
        # test root url = https://www.yelp.com/biz/julianas-pizza-brooklyn-5?osq=pizza

        #extracat the biz information to put into mongodb.

        pizza_name = clean_parsed_result(response.xpath('//h1/text()').extract_first())
        searchable_name = make_searchable_name(pizza_name)
        pizza_address = clean_parsed_result(response.xpath('//address[not(contains(@itemprop, "address"))]/text()').extract_first())
        pizza_phone = clean_parsed_result(response.xpath("//*[@class='biz-phone']/text()").extract_first())

        #extracting the review list
        reviews = response.xpath("//div[@class='review review--with-sidebar']").extract()

        for review in reviews:
            #for each review, send it to lxml.html so we can use xpath to extract individual review data
            review_tree = html.fromstring(review)
            reviewer_name = extract_first(review_tree.xpath("//li[@class='user-name']/a/text()"))
            reviewer_image = extract_first(review_tree.xpath("//img[@class='photo-box-img']/@src"))
            reviewer_location = extract_first(review_tree.xpath("//li[@class='user-location responsive-hidden-small']/b/text()"))
            reviewer_rating = review_tree.xpath("//div[contains(@class,'i-stars--regular')]/@class")[0].split(' ')[1].replace('i-stars--regular-', '')
            review_date = clean_parsed_result(extract_first(review_tree.xpath("//span[@class='rating-qualifier']/text()")))

            #Need special handling to extract review content data
            raw_review_contents = review_tree.xpath("//div[@class='review-content']//p[@lang='en']/text()")
            review_content = ""

            for raw_review_content in raw_review_contents:
                review_content += raw_review_content + "<br>"

            #yielding the result out to insert through mongodb
            yield {
                'pizza_name': pizza_name,
                'searchable_name' : searchable_name,
                'pizza_address': pizza_address,
                'pizza_phone': pizza_phone,
                'reviewer_name': reviewer_name,
                'reviewer_image': reviewer_image,
                'reviewer_location': reviewer_location,
                'reviewer_rating': float(reviewer_rating),
                'review_date': review_date,
                'review_date_unix': convert_to_unix_timestamp(review_date),
                'review_content': review_content

            }

        #See if we can find the next_url
        next_url = response.xpath("//a[@class='u-decoration-none next pagination-links_anchor']/@href").extract_first()
        current_page = get_current_page(response.url)
        if current_page <= PAGE_CUT_OFF:
            if next_url:
                yield Request(next_url, callback=self.parse_pizza)

